# ğŸ§— The Iron-Clad Data Science Ladder

> _"If it isn't in a repo, it doesn't exist."_

This repository documents a structured, no-shortcuts journey from **Python Engineer â†’ Data Scientist â†’ ML Engineer â†’ Deep Learning â†’ NLP â†’ Computer Vision â†’ Robotics**. The full plan is divided into 6 coding phases, each building directly on the last, and each ending with a real capstone project.

---

## ğŸ“‹ The Daily Operating System (3â€“5 Hours/Day)

Every study day follows the same structure to fight the memory leak problem:

| Hour                             | Activity                                                                                        |
| -------------------------------- | ----------------------------------------------------------------------------------------------- |
| **Hour 1** â€” The Intake          | Theory only. Watch videos / read docs. Hard stop at 1 hour.                                     |
| **Hours 2â€“3** â€” The Lab          | Write the code from scratch, without looking at the tutorial. If you peek, you reset the timer. |
| **Hour 4** â€” The Integration     | Add what you learned today to yesterday's project. Keep building.                               |
| **Hour 5** â€” Review _(optional)_ | Debugging and git commits. No code stays on your PC overnight.                                  |

---

## ğŸ—ºï¸ Full Learning Roadmap

### ğŸ—ï¸ Phase 0 â€” The Python Engineer _(Weeks 1â€“4)_

**Goal:** Stop writing "Scripting Python" and start writing "Software Python." Data science pipelines are complex software systems.

| Topic                           | The Real Task                                                                                   | Retention Check                                                |
| ------------------------------- | ----------------------------------------------------------------------------------------------- | -------------------------------------------------------------- |
| **1. Git**                      | Create a repo. Learn `init`, `add`, `commit`, `push`.                                           | Rule: No code stays on your PC overnight. Push everything.     |
| **2. Modular Python & Logging** | Create a `logger.py` module. Import it into a main script.                                      | Stop using `print()`. Use `logging.info()`.                    |
| **3. OOP & Exceptions**         | Create a `DataHandler` class. It must ingest a CSV and crash gracefully if the file is missing. | If your code crashes with a raw traceback, you fail. Catch it. |
| **4. SQLite & Persistence**     | Save your processed data to `data.db` via your class methods.                                   | Write a query to fetch the last 5 entries.                     |

ğŸ”¥ **Capstone 1 â€” The "Life Logger" CLI**

> A terminal app to track your 3â€“5 hours of study.
>
> - **Input:** `python run.py --add "Studied Pandas" --hours 3`
> - **Logic:** A `StudySession` class validates input (no negative hours)
> - **Storage:** Saves to SQLite
> - **Output:** `logging` writes "Session saved" to `app.log`
> - **Git:** Push it.

ğŸ“ **Folder:** `Phase 0/` â† _You are here_

---

### ğŸ“Š Phase 1 â€” The Data Mechanic _(Weeks 5â€“9)_

**Goal:** You cannot model what you cannot clean.
**Focus:** Pandas, NumPy, Visualization, Statistics.

| Topic                      | The Real Task                                                                | Retention Check                                     |
| -------------------------- | ---------------------------------------------------------------------------- | --------------------------------------------------- |
| **5. NumPy & Vectors**     | Manually implement Mean Squared Error using numpy arrays â€” no loops allowed. | Speed test: Loop vs Vectorization.                  |
| **6. Pandas Core**         | Load a messy dataset. Fix dates, handle NaNs, filter rows.                   | Do it without opening the CSV in Excel.             |
| **7. EDA & Viz (Seaborn)** | Plot distributions. Find outliers. Write a paragraph explaining WHY.         | A chart without a conclusion is useless.            |
| **8. Probability & Stats** | Generate a Normal Distribution in code. Calculate Z-scores for your data.    | Use `scipy` to prove if two columns are correlated. |

ğŸ”¥ **Capstone 2 â€” The "Automated Analyst"**

> A script that takes ANY raw CSV and generates a full report.
>
> - **Ingest:** `pd.read_csv()` on a generic file
> - **Clean:** Auto-fill missing values with column mean (using OOP skills from Phase 0)
> - **Visual:** Generate a `.png` histogram for every numeric column
> - **Stats:** Log the "Skewness" of every column to a file

ğŸ“ **Folder:** `Phase 1/`

---

### ğŸ¤– Phase 2 â€” Machine Learning _(Weeks 10â€“18)_

**Goal:** Predict the future.
**Focus:** Scikit-Learn, Algorithms, Feature Engineering.

| Topic                             | The Real Task                                                 | Retention Check                                  |
| --------------------------------- | ------------------------------------------------------------- | ------------------------------------------------ |
| **9. Linear/Logistic Regression** | Predict Housing Prices. Predict Diabetes.                     | Plot the Decision Boundary or Regression Line.   |
| **10. Trees & Forests**           | Visualize a single Decision Tree. Then train a Random Forest. | Compare accuracy. Why did RF win? Write it down. |
| **11. Boosting (XGBoost)**        | The holy grail of tabular data. Tune hyperparameters.         | Beat your Random Forest score.                   |
| **12. Unsupervised (K-Means)**    | Cluster customers based on spending.                          | Visualize the clusters in 2D using PCA.          |
| **13. Evaluation Metrics**        | Implement Precision/Recall manually.                          | Don't just trust `accuracy_score`.               |

ğŸ”¥ **Capstone 3 â€” The "Streamlit Predictor"**

> Your first web app.
>
> - **Model:** Train an XGBoost model on the Titanic or Heart Disease dataset
> - **Pipeline:** Use `sklearn.pipeline` to bundle cleaning + modelling
> - **UI:** Build a Streamlit app with sliders for user input and a "Predict" button
> - **Deployment:** Run locally. _(Bonus: deploy to Streamlit Cloud)_

ğŸ“ **Folder:** `Phase 2/` _(coming soon)_

---

### ğŸ§  Phase 3 â€” Deep Learning _(Weeks 19â€“22)_

**Goal:** Beyond tabular data. Understanding complexity.
**Focus:** PyTorch, Neural Nets. _(We switch to PyTorch here â€” it is the language of Research and Robotics.)_

| Topic                       | The Real Task                                           | Retention Check                                 |
| --------------------------- | ------------------------------------------------------- | ----------------------------------------------- |
| **14. Tensors & Gradients** | Manual Backpropagation (Micrograd style).               | Understand `requires_grad=True`.                |
| **15. ANN â€” The Basics**    | Build a Feed-Forward net for MNIST (Digit recognition). | Plot the Loss Curve over epochs.                |
| **16. Optimization**        | SGD vs Adam. Experiment with Learning Rates.            | Break the model (make it diverge), then fix it. |

ğŸ”¥ **Capstone 4 â€” The "Digit Recognizer" from Scratch**

> Build a neural network **without** a high-level API wrapper first, then rebuild it properly with `PyTorch nn.Module`.

ğŸ“ **Folder:** `Phase 3/` _(coming soon)_

---

### ğŸ—£ï¸ Phase 4 â€” NLP _(Weeks 23â€“30)_

**Goal:** Teaching machines to read.
**Focus:** Text, RNNs, Transformers.

| Topic                | The Real Task                             | Retention Check                                    |
| -------------------- | ----------------------------------------- | -------------------------------------------------- |
| **17. Embeddings**   | Word2Vec. Visualizing words in 3D space.  | Find the closest word to "King" âˆ’ "Man" + "Woman". |
| **18. RNN/LSTM/GRU** | Text Classification (Sentiment Analysis). | Why does Vanishing Gradient happen? Simulate it.   |
| **19. Transformers** | The Attention Mechanism. HuggingFace.     | Fine-tune BERT on a custom dataset.                |

ğŸ”¥ **Capstone 5 â€” The "Context Chatbot"**

> A bot that answers questions based on a PDF you upload.
>
> - **Tech:** HuggingFace Transformers + FAISS (Vector DB)
> - **Task:** RAG (Retrieval Augmented Generation)

ğŸ“ **Folder:** `Phase 4/` _(coming soon)_

---

### ğŸ‘ï¸ Phase 5 â€” Computer Vision _(Weeks 31â€“38)_

**Goal:** Teaching machines to see.
**Focus:** CNNs, Images, Object Detection. _(This is the bridge to Robotics.)_

| Topic                     | The Real Task                                                    | Retention Check                                      |
| ------------------------- | ---------------------------------------------------------------- | ---------------------------------------------------- |
| **20. CNNs**              | Build a ConvNet for CIFAR-10 (Image classification).             | Visualize the "Feature Maps" (what the filter sees). |
| **21. Transfer Learning** | Use ResNet50. Fine-tune it to classify "Hot Dog vs Not Hot Dog". | Freeze layers vs Unfreeze layers.                    |
| **22. Object Detection**  | YOLO (You Only Look Once). Detect cars in video.                 | Draw bounding boxes in real-time.                    |

ğŸ”¥ **Capstone 6 â€” The "Vision Security System"**

> Webcam integration with real-time detection.
>
> - **Input:** OpenCV reads webcam feed
> - **Model:** YOLOv8 detects "Person"
> - **Logic:** If "Person" detected, log timestamp to SQLite _(using Phase 0 skills!)_

ğŸ“ **Folder:** `Phase 5/` _(coming soon)_

---

### ğŸ¤– Final Frontier â€” Robotics Prep

**Goal:** Apply everything to the physical world.

- **ROS2** (Robot Operating System) â€” The middleware of robotics
- **SLAM** â€” Simultaneous Localization and Mapping
- **Reinforcement Learning** â€” Teaching a robot to walk (simulated)

---

## âš ï¸ The "Senior Dev" Retention Protocols

> These rules apply to **every single day** of the journey:

1. **The 20-Minute Rule** â€” Stuck? Debug for 20 minutes. Read the error. Print the variables. _Then_ ask AI.
2. **Spiral Learning** â€” Every project must use a **database** (Phase 0 skill) and a **visualization** (Phase 1 skill). Never drop the basics.
3. **Code Reviews** â€” Once a week, ask ChatGPT: _"Roast my code. Tell me why it is not production ready."_ Then fix it.

---

---

# Phase 0 â€” Python Foundations & Data Engineering (Days 1â€“15)

> **Goal:** Build a solid, professional-grade Python foundation â€” from basic syntax all the way through Object-Oriented Programming, modular design, database integration, and a complete capstone application.

---

## ğŸ—ºï¸ Phase Overview

| Day(s)      | Theme                           | Key Skill                                      |
| ----------- | ------------------------------- | ---------------------------------------------- |
| Day 1       | Python Basics & Warmup          | Variables, loops, conditionals                 |
| Day 2       | Algorithms & Logic              | Searching, sorting, string manipulation        |
| Day 3       | Data Structures                 | Lists, dictionaries, slicing                   |
| Day 4       | Tuples & Comprehensions         | Multiple returns, list comprehensions          |
| Day 5       | Modules & Error Handling        | Import system, try/except                      |
| Day 6       | Recursion & Sets                | Recursion, set operations, frequency analysis  |
| Day 7       | Code Review & Refactoring       | Reading code, Pythonic patterns                |
| Day 8       | Modular Architecture            | Separation of concerns, `__main__` guard       |
| Day 9       | OOP Fundamentals                | Classes, constructors, logging                 |
| Day 10 & 11 | Advanced OOP                    | Inheritance, polymorphism, magic methods       |
| Day 12      | SQLite Databases                | CRUD operations, `DatabaseManager` class       |
| Day 13      | Base Classes & Design Patterns  | Abstract base classes, Template Method pattern |
| Day 14      | Full Data Pipeline              | End-to-end: input â†’ process â†’ database         |
| Day 15      | Capstone Project 1 â€” LifeLogger | Full CLI application with SQLite persistence   |

---

## ğŸ“… Day-by-Day Breakdown

### Day 1 â€” Python Basics & Warmup

**Focus:** Getting comfortable with Python syntax and fundamental building blocks.

- **Variables & Data Types** â€” Working with `str` and `int`
- **f-Strings** â€” Dynamic string formatting with variable interpolation
- **Functions** â€” Defining and calling simple functions (e.g., `square`)
- **Lists** â€” Creating and iterating through collections of numbers
- **For Loops** â€” Processing list elements with `for`
- **Conditionals** â€” `if` statements for filtering (e.g., finding even numbers)

ğŸ“ Files: `day1_warmup.py`

---

### Day 2 â€” Algorithms & Logic

**Focus:** Implementing classic algorithm patterns from scratch without relying on built-ins.

- **Finding Maximum** â€” Manual search through a list for the largest value
- **Counting** â€” Iterating and counting elements that match a condition (e.g., odd numbers)
- **String Reversal** â€” Manually reversing a string character-by-character
- **FizzBuzz** â€” The classic modulo-based interview problem
- **Accumulation** â€” Summing numbers that meet certain criteria (e.g., evens only)
- **Filtering by Property** â€” Building new lists based on string characteristics (vowel starts)

ğŸ“ Files: `day2.py`

---

### Day 3 â€” Data Structures & Logic

**Focus:** Deeper work with Python's core data structures â€” lists, dictionaries, and slices.

- **List Slicing** â€” Advanced techniques: reversing with `[::-1]`, steps, sub-lists
- **Dictionaries** â€” Accessing `.keys()`, `.values()`, `.items()`
- **In-place List Transformation** â€” Squaring all elements of a list
- **String Processing** â€” Counting words that start with vowels
- **Frequency Counter** â€” Manually tallying word frequencies using nested loops and dicts
- **Second Largest** â€” Algorithm to find the 2nd largest number without sorting

ğŸ“ Files: `day3.py`

---

### Day 4 â€” Tuples & Data Processing

**Focus:** Working with tuples, list comprehensions, and more complex data transformations.

- **Multiple Return Values** â€” Returning `(min, max, sum)` as a tuple from a single function
- **String Cleaning** â€” Stripping whitespace and normalizing case across a list
- **Tuples** â€” Storing paired data (e.g., `(word, length)`) in a list of tuples
- **List Comprehensions** â€” Concise one-line alternatives to `for` loops
- **Dictionary Construction** â€” Merging two parallel lists (keys + values) into a dict
- **Combined Filter & Transform** â€” Squaring only odd numbers in one pass
- **Categorization** â€” Grouping data into `pass`/`fail` buckets using a dict of lists

ğŸ“ Files: `day4.py`

---

### Day 5 â€” Modules & Error Handling

**Focus:** Multi-file Python projects and defensive programming with error handling.

- **Modules & Imports** â€” Splitting code into `utils`, `main`, and logic files
- **Nested Lists** â€” Flattening lists of lists and processing sub-elements
- **List of Dictionaries** â€” Extracting targeted fields (e.g., names) from structured data
- **Dictionary Filtering** â€” Finding entries that meet threshold conditions (top scorers)
- **Error Handling** â€” `try-except` blocks covering `ZeroDivisionError` and `ValueError`
- **String Formatting** â€” Specialized output formatting for user-friendly display

ğŸ“ Files: `day5.py`, `day5_utils.py`, `day5_main.py`

---

### Day 6 â€” Advanced Logic & Recursion

**Focus:** Complex algorithms including recursion and deep data analysis.

- **Complex List Processing** â€” Averaging dictionaries, handling empty-data edge cases
- **Error Handling** â€” Managing `ZeroDivisionError` when computing averages
- **Frequency Analysis** â€” Finding the most frequently occurring word in a dataset
- **Recursion** â€” `deep_flatten()` to flatten arbitrarily nested lists of any depth
- **Set Operations** â€” Using `set()` for unique values; finding the 2nd largest unique
- **Data Cleaning** â€” Stripping special characters from strings with `str.strip(chars)`
- **Character Frequency** â€” Counting per-character occurrence in text (case-insensitive, ignoring whitespace)

ğŸ“ Files: `day6.py`

---

### Day 7 â€” Code Review & Refactoring

**Focus:** A dedicated review day â€” no new code, but critical learning through analysis.

- **Code Review** â€” Deep reading of Day 6 code to identify inefficiencies and code smells
- **Pythonic Thinking** â€” Understanding when and how to replace brute-force logic with idiomatic Python
- **Reflection** â€” Documenting observations and planned improvements for future days

ğŸ“ Files: `day7.py` _(minimal â€” reflection notes)_

---

### Day 8 â€” Modular Architecture & Execution Blocks

**Focus:** Structuring a multi-file Python project with clean separation of concerns.

- **Separation of Concerns** â€” Splitting into `data`, `utils`, and `main` modules:
  - `day8_data.py` â€” Raw data storage
  - `day8_utils.py` â€” Reusable logic and helper functions
  - `day8_mian.py` â€” Application entry point
- **`if __name__ == "__main__"` Guard** â€” Preventing unintended code execution on import
- **Local Imports** â€” Pulling specific variables and functions from sibling modules
- **Data Cleaning** â€” Stripping numbers, special characters, and whitespace from strings
- **Safe Operations** â€” Defensive functions that handle edge cases like empty lists (`safe_average`)

ğŸ“ Files: `day8_data.py`, `day8_utils.py`, `day8_mian.py`

---

### Day 9 â€” Object-Oriented Programming (OOP) & Logging

**Focus:** The pivotal transition from functional to object-oriented code, plus professional logging.

- **Classes & Objects** â€” Defining `DataProcessor` and `TextCleaner` blueprints and creating instances
- **Constructors (`__init__`)** â€” Initializing object state at creation time
- **Methods** â€” Encapsulating logic inside class functions
- **Logging Module** â€” Replacing `print()` with `logging`; configuring levels (INFO, ERROR), message formats, and file output (`app.log`)
- **Refactoring** â€” Converting standalone functions into class methods
- **List Comprehensions** â€” Writing clean, concise data-cleaning loops

ğŸ“ Files: `day9_processors.py`, `day9_cleaners.py`, `day9_main.py`

---

### Days 10 & 11 â€” Advanced OOP: Inheritance, Polymorphism & Magic Methods

**Focus:** Taking OOP to the next level â€” building class hierarchies and making objects behave like native Python types.

- **Inheritance** â€” `AdvancedDataProcessor` inherits from `DataProcessor`; child reuses parent logic
- **Polymorphism** â€” Overriding `safe_average()` in the child class with extended behavior
- **`super()`** â€” Calling `super().__init__()` and `super().method()` to chain parent logic cleanly
- **Magic (Dunder) Methods** â€” Implementing `__str__`, `__len__`, `__getitem__` so objects behave like built-in types
- **Custom Exceptions** â€” Defining `InvalidDataError` in `exceptions.py` for domain-specific error tracking
- **Type Checking** â€” Using `isinstance()` to validate input data types inside constructors
- **Extending Classes** â€” Adding new capabilities (`calculate_median`) to child classes

ğŸ“ Files: `day10_processors.py`, `day10_advanced_processors.py`, `day10_main.py`, `exceptions.py`

---

### Day 12 â€” SQLite Database Integration

**Focus:** Persistent data storage â€” saving program output to a real database.

- **SQLite & `sqlite3`** â€” Connecting to a local `.db` file; creating and querying tables
- **CRUD Operations** â€” Executing `INSERT`, `SELECT`, and `DELETE` SQL statements in Python
- **`DatabaseManager` Class** â€” Encapsulating all database logic inside a dedicated OOP class
- **Data Persistence** â€” Saving processed results (e.g., averages) that survive program restarts
- **Timestamps** â€” Using `datetime` to record exactly when each entry was saved
- **Resource Management** â€” Properly closing DB connections to avoid memory/file-lock issues

ğŸ“ Files: `day12_db.py`, `day12_main.py`, `day12_processors.py`

---

### Day 13 â€” Base Classes & Design Patterns

**Focus:** Establishing robust, scalable OOP architecture using abstract base classes.

- **Base Classes** â€” `BaseProcessor` defines the mandatory interface for all processor subclasses
- **Abstract Methods (via `NotImplementedError`)** â€” Forcing child classes to implement `_validate()` and `process()`
- **Template Method Pattern** â€” The parent class controls execution flow (calls `_validate` in `__init__`), children fill in the details
- **Inheritance** â€” `DataProcessor` and `TextCleaner` both inherit from `BaseProcessor`
- **Dictionary Returns** â€” `process()` returns a structured `dict` of results for flexible downstream use

ğŸ“ Files: `day13_base_processor.py`, `day13_processors.py`, `day13_cleaners.py`, `day13_main.py`

---

### Day 14 â€” Full Data Pipeline: Input â†’ Process â†’ Database

**Focus:** Connecting all previous concepts into a complete, end-to-end data processing pipeline.

- **`DatabaseHandler` Class** â€” Dedicated class managing SQLite connection lifecycle, table creation, and data insertion
- **End-to-End Data Flow** â€” Input â†’ Validation â†’ Processing â†’ Persistent storage in one seamless pipeline
- **Exception Handling** â€” Specific `try-except` around database connections and query execution failures
- **Extensive Logging** â€” Every database event (success and failure) logged for production-grade debugging
- **Structured Storage** â€” Calculated statistics (`positives_count`, `average`, `min`, `max`) saved to `Processed_Data` table

ğŸ“ Files: `day14_database_methods.py`, `day14_processors.py`, `day14_main.py`

---

### Day 15 â€” Capstone Project 1: LifeLogger ğŸ†

**Focus:** Building a real, feature-complete console application combining everything learned in Phase 0.

**LifeLogger** is a CLI time-tracker that lets you log how many hours you spend on any topic, saves every entry permanently, and lets you review your full history.

- **Interactive CLI** â€” Prompts users for `Topic` and `Time Spent` in a clean input loop
- **Input Validation** â€” Ensures time is a numeric value and prevents negative entries
- **SQLite Persistence** â€” Every log entry saved to `LifeLogger_db` (topics, hours, timestamp)
- **History Reporting** â€” Displays all historical entries with their timestamps on demand
- **Custom Exceptions** â€” Domain-specific error classes in `exceptions.py` for clean error reporting
- **Application Logging** â€” Internal events recorded to `app.log` for debugging

ğŸ“ Files: `day15_main.py`, `day15_data_collector.py`, `day15_database_methods.py`, `exceptions.py`

---

## ğŸ¯ Phase 0 Skills Summary

By the end of Phase 0, the following professional Python skills were acquired:

| Category             | Skills Gained                                                                       |
| -------------------- | ----------------------------------------------------------------------------------- |
| **Python Core**      | Variables, loops, conditionals, functions, list/dict/tuple, comprehensions, slicing |
| **Algorithms**       | Searching, sorting variants, frequency analysis, recursion, set operations          |
| **Error Handling**   | `try-except`, custom exception classes, input validation                            |
| **Modular Design**   | Multi-file structure, imports, `__main__` guard, separation of concerns             |
| **OOP**              | Classes, inheritance, polymorphism, magic methods, base classes, design patterns    |
| **Logging**          | `logging` module, log levels, file handlers                                         |
| **Databases**        | SQLite with `sqlite3`, CRUD, schema design, connection management                   |
| **Project Building** | Full CLI application with persistence, validation, and history reporting            |
